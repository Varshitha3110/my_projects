{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d58ae3",
   "metadata": {},
   "source": [
    "# ðŸ“§ Spam Classification using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fdb09e",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Introduction\n",
    "\n",
    "### Why is Spam Classification Important?\n",
    "\n",
    "Spam emails are unsolicited messages sent in bulk, often for advertising, phishing, or malicious purposes. These emails can be annoying at best and dangerous at worst, as they may contain fraudulent links, scams, or malware.\n",
    "\n",
    "With the increasing volume of emails received daily, manually identifying and filtering spam emails is impractical. This is where **Machine Learning (ML)** comes in. By leveraging **Natural Language Processing (NLP)** techniques, we can automate spam detection with high accuracy.\n",
    "\n",
    "### Goal of This Project\n",
    "\n",
    "The primary objective of this project is to classify emails as **spam** or **ham (not spam)** using machine learning techniques. We will:\n",
    "\n",
    "1. **Process and clean** the email dataset.\n",
    "2. **Convert textual data** into numerical features using **TF-IDF Vectorization**.\n",
    "3. **Train a Logistic Regression model** to classify emails.\n",
    "4. **Evaluate model performance** using metrics like **accuracy score**.\n",
    "5. **Suggest improvements** for future work.\n",
    "\n",
    "This project is a **Level 2 Data Science Project**, which means we go beyond basic dataset exploration and implement more advanced **feature engineering**, **machine learning algorithms**, and **evaluation techniques**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde7222",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec729c66",
   "metadata": {},
   "source": [
    "### 2.1 Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce247a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e557fe89",
   "metadata": {},
   "source": [
    "\n",
    "### Why Are These Libraries Important?\n",
    "\n",
    "1. **NumPy (`numpy`)**: Provides support for large, multi-dimensional arrays and matrices. It is particularly useful for handling numerical operations efficiently.\n",
    "\n",
    "2. **Pandas (`pandas`)**: A powerful data analysis library used to load, manipulate, and preprocess tabular datasets like CSV files.\n",
    "\n",
    "3. **Matplotlib (`matplotlib.pyplot`)**: A popular data visualization library that helps us create graphs and charts to analyze dataset characteristics.\n",
    "\n",
    "4. **Seaborn (`seaborn`)**: Built on top of Matplotlib, it provides additional plotting capabilities for statistical visualizations.\n",
    "\n",
    "5. **Scikit-Learn (`sklearn`)**: A machine learning library with utilities for data preprocessing, model training, and evaluation.\n",
    "\n",
    "   - `train_test_split`: Splits data into training and testing sets.\n",
    "   - `LogisticRegression`: A statistical model for binary classification.\n",
    "   - `TfidfVectorizer`: Converts textual data into numerical features using **TF-IDF (Term Frequency-Inverse Document Frequency)**.\n",
    "   - `accuracy_score`: Computes the accuracy of model predictions.\n",
    "   - `classification_report`: Provides a detailed breakdown of precision, recall, and F1-score.\n",
    "   - `confusion_matrix`: Displays true positives, false positives, true negatives, and false negatives.\n",
    "\n",
    "With these libraries, we can effectively process and classify emails.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd34587b",
   "metadata": {},
   "source": [
    "### 2.2 Loading and Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e93d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"mail_data.csv\")\n",
    "print(\"Dataset Overview:\")\n",
    "print(df.head())  # Display first few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feccf83f",
   "metadata": {},
   "source": [
    "\n",
    "### Understanding the Dataset\n",
    "\n",
    "Our dataset consists of two main columns:\n",
    "\n",
    "1. **Category**: Labels indicating whether the email is **\"spam\"** or **\"ham\"** (not spam).\n",
    "2. **Message**: The actual email text.\n",
    "\n",
    "Our goal is to use the **Message** column to predict the **Category**.\n",
    "\n",
    "### Sample Data:\n",
    "\n",
    "| Index | Category | Message |\n",
    "|--------|----------|------------|\n",
    "| 0 | ham | Hello, how are you? |\n",
    "| 1 | spam | Congratulations! You won a free iPhone! Click here to claim. |\n",
    "| 2 | ham | Are we still meeting tomorrow? |\n",
    "| 3 | spam | Urgent! Your account has been compromised. Enter your password now. |\n",
    "\n",
    "From the example above, we can observe that spam messages often contain words like **\"Congratulations,\" \"Urgent,\" \"Click here,\"** or **\"Free.\"**\n",
    "\n",
    "To proceed, we will clean and preprocess this text data to improve our model's accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daedd6b",
   "metadata": {},
   "source": [
    "### 2.3 Handling Missing and Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ec255",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Checking for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "duplicates = df.duplicated().sum()\n",
    "\n",
    "# Removing missing values and duplicates\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f\"Missing values: {missing_values.sum()}\")\n",
    "print(f\"Duplicate rows removed: {duplicates}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01de2bae",
   "metadata": {},
   "source": [
    "\n",
    "### Why Handle Missing and Duplicate Values?\n",
    "\n",
    "- **Missing values** can disrupt the training process, leading to inaccurate predictions.\n",
    "- **Duplicate rows** can bias the model, causing it to learn incorrect patterns.\n",
    "- By removing both, we ensure a **clean and balanced dataset** for training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985c19ff",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a6dc9",
   "metadata": {},
   "source": [
    "### 3.1 Converting Labels into Numerical Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf6d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"label\"] = df[\"Category\"].map({\"spam\": 1, \"ham\": 0})  # Mapping spam as 1 and ham as 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fe0775",
   "metadata": {},
   "source": [
    "\n",
    "### Why Convert Labels?\n",
    "\n",
    "Most machine learning models cannot work directly with **text labels**. They require **numerical representations**.\n",
    "\n",
    "- **Spam (1)**: Indicates an email is unwanted or fraudulent.\n",
    "- **Ham (0)**: Indicates a normal, non-spam email.\n",
    "\n",
    "This transformation allows the model to learn patterns associated with each category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ef81e6",
   "metadata": {},
   "source": [
    "### 3.2 Transforming Text Data using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7955ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "X = vectorizer.fit_transform(df[\"Message\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a38b8",
   "metadata": {},
   "source": [
    "\n",
    "### Why Use TF-IDF?\n",
    "\n",
    "**TF-IDF (Term Frequency - Inverse Document Frequency)** is a statistical method that converts text into numerical values by analyzing the importance of words in a document.\n",
    "\n",
    "- **High TF-IDF Score**: Words that appear frequently in a specific document but rarely elsewhere (e.g., \"lottery\" in spam emails).\n",
    "- **Low TF-IDF Score**: Common words found across multiple documents (e.g., \"the,\" \"is,\" \"and\").\n",
    "\n",
    "This method ensures that our model focuses on words that truly differentiate spam from ham.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f8cda",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3890b6d",
   "metadata": {},
   "source": [
    "### 4.1 Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df[\"label\"], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1dad0",
   "metadata": {},
   "source": [
    "\n",
    "### Why Split Data?\n",
    "\n",
    "- **Training Set (80%)**: Used to teach the model.\n",
    "- **Testing Set (20%)**: Used to evaluate performance.\n",
    "\n",
    "A good split ensures the model generalizes well to unseen emails.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98870121",
   "metadata": {},
   "source": [
    "### 4.2 Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee59e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
